<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="氨基酸小童鞋的博客" href="https://zhihao-a.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="氨基酸小童鞋的博客" href="https://zhihao-a.github.io/atom.xml"><link rel="alternate" type="application/json" title="氨基酸小童鞋的博客" href="https://zhihao-a.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="Transformer"><link rel="canonical" href="https://zhihao-a.github.io/2023/12/17/Transformer%E7%9B%B8%E5%85%B3%E6%96%87%E7%8C%AE%E6%80%BB%E7%BB%93/"><title>Transformer相关文献总结 | 氨基酸小童鞋 = 氨基酸小童鞋的博客 = 氨基酸小童鞋的博客</title><meta name="generator" content="Hexo 7.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">Transformer相关文献总结</h1><div class="meta"><span class="item" title="创建时间：2023-12-17 18:49:33"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2023-12-17T18:49:33+08:00">2023-12-17</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>2.3k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>2 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">氨基酸小童鞋</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://s3.bmp.ovh/imgs/2023/12/17/aef587a6506849f9.jpg"></li><li class="item" data-background-image="https://s3.bmp.ovh/imgs/2023/12/17/d381655addb17c95.jpg"></li><li class="item" data-background-image="https://s3.bmp.ovh/imgs/2023/12/17/5e4a3be0bf1ee4cc.jpg"></li><li class="item" data-background-image="https://s3.bmp.ovh/imgs/2023/12/17/003de54d666d08f8.jpg"></li><li class="item" data-background-image="https://s3.bmp.ovh/imgs/2023/12/17/07607a8d73361125.jpg"></li><li class="item" data-background-image="https://s3.bmp.ovh/imgs/2023/12/17/694c7ce95dcbdbb7.jpg"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zhihao-a.github.io/2023/12/17/Transformer%E7%9B%B8%E5%85%B3%E6%96%87%E7%8C%AE%E6%80%BB%E7%BB%93/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="氨基酸小童鞋"><meta itemprop="description" content="氨基酸小童鞋的博客, 氨基酸小童鞋的博客"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="氨基酸小童鞋的博客"></span><div class="body md" itemprop="articleBody"><p>Transformer 网络完整结构</p><p>主要分为</p><ul><li>positional+embedding<ul><li>positional Encoding</li><li>Embedding</li></ul></li><li>编码器层<ul><li>多头注意力子层</li><li>层归一化</li><li>多层前馈网络层</li><li></li></ul></li><li>解码器层</li><li></li></ul><h1 id="huggingface-下载模型指南"><a class="anchor" href="#huggingface-下载模型指南">#</a> huggingFace 下载模型指南</h1><h2 id="1-huggingface-clihf_transfer"><a class="anchor" href="#1-huggingface-clihf_transfer">#</a> 1. huggingface-cli+hf_transfer</h2><p><code>huggingface-cli</code> 和 <code>hf_transfer</code> 是 hugging face 官方提供的专门为下载而设计的工具链。前者是一个命令行工具，后者是下载加速模块。</p><h3 id="11-huggingface-cli"><a class="anchor" href="#11-huggingface-cli">#</a> 1.1 huggingface-cli</h3><p><code>huggingface-cli</code> 隶属于 <code>huggingface_hub</code> 库，不仅可以下载模型、数据，还可以登录 huggingface、上传模型、数据等。huggingface-cli 属于官方工具，其长期支持肯定是最好的。<strong>优先推荐！</strong></p><p><strong>安装依赖</strong></p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U huggingface_hub</span><br></pre></td></tr></table></figure><p><em>注意：huggingface_hub 依赖于 Python&gt;=3.8，此外需要安装 0.17.0 及以上的版本，推荐 0.19.0+。</em></p><p><strong>基本用法</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">huggingface-cli download --resume-download bigscience/bloom-560m --local-dir bloom-560m</span><br></pre></td></tr></table></figure><p><strong>下载数据集</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">huggingface-cli download --resume-download --repo-type dataset lavita/medical-qa-shared-task-v1-toy</span><br></pre></td></tr></table></figure><p>值得注意的是，有个 <code>--local-dir-use-symlinks False</code> 参数可选，因为 huggingface 的工具链默认会使用符号链接来存储下载的文件，导致 <code>--local-dir</code> 指定的目录中都是一些 “链接文件”，真实模型则存储在 <code>~/.cache/huggingface</code> 下，如果不喜欢这个可以用 <code>--local-dir-use-symlinks False</code> 取消这个逻辑。</p><p>但我不太喜欢取消这个参数，<strong>其最大方便点在于，调用时可以用模型名直接引用模型，而非指定模型路径。</strong></p><p>什么意思呢？我们知道， <code>from_pretrain</code> 函数可以接收一个模型的 id，也可以接收模型的存储路径。</p><p>假如我们用浏览器下载了一个模型，存储到服务器的 <code>/data/gpt2</code> 下了，调用的时候你得写模型的绝对路径</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AutoModelForCausalLM.from_pretrained(&quot;/data/gpt2&quot;)</span><br></pre></td></tr></table></figure><p>然而如果你用的 <code>huggingface-cli download gpt2 --local-dir /data/gpt2</code> 下载，即使你把模型存储到了自己指定的目录，但是你仍然可以简单的用模型的名字来引用他。即：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AutoModelForCausalLM.from_pretrained(&quot;gpt2&quot;)</span><br></pre></td></tr></table></figure><p>原理是因为 huggingface 工具链会在 <code>.cache/huggingface/</code> 下维护一份模型的<strong>符号链接</strong>，无论你是否指定了模型的存储路径 ，缓存目录下都会链接过去，这样可以避免自己忘了自己曾经下过某个模型，此外调用的时候就很方便。</p><p>所以用了官方工具，既可以方便的用模型名引用模型，又可以自己把模型集中存在一个自定义的路径，方便管理。</p><p>当然，该工具目前还是有一些缺点的：</p><p>一是其 ** 存储逻辑不太直观，** 如上所属的缓存与链接逻辑，使得新手经常询问，模型究竟下载到哪里去了？</p><p>二是<strong>不支持单文件多线程</strong>。目前的行为是多文件并行，一次性会同时下载多个文件。</p><p>三是<strong>遇到网络中断会报错退出，不会自动重试</strong>，需要重新手动执行。<strong>【更新，v0.19.0 已支持自动重试】</strong></p><h3 id="12-hf_transfe"><a class="anchor" href="#12-hf_transfe">#</a> 1.2 hf_transfe</h3><p><code>hf_transfer</code> 依附并兼容 <code>huggingface-cli</code> ，是 hugging face 官方专门为提高下载速度基于 Rust 开发的一个模块，开启后在带宽充足的机器上可以跑到 500MB/s。本人实测了三台不同网络环境的机器，确实有黑科技啊，都把带宽跑满了（千兆）。</p><p>然而缺点是：</p><ul><li><strong>1. 没有进度条【更正，v0.19.0 + 开始支持进度条了】：是真的没有进度条，有进度条说明你没有开启成功。</strong></li><li><strong>2. 鲁棒性差，遇到网络不稳定会报错，并提示用户考虑关闭该模块提高容错性。可能这个模块还没有很成熟吧，对国内这种丢包率高的网络还是水土不服。</strong></li></ul><p>尽管如此，还是推荐给大家，看各自网络情况吧。</p><p>项目地址：<span class="exturl" data-url="aHR0cHM6Ly9saW5rLnpoaWh1LmNvbS8/dGFyZ2V0PWh0dHBzJTNBLy9naXRodWIuY29tL2h1Z2dpbmdmYWNlL2hmX3RyYW5zZmVy">https://github.com/huggingface/hf_transfer</span>。</p><p><strong>开启方法</strong></p><p><strong>(1) 安装依赖</strong></p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U hf-transfer</span><br></pre></td></tr></table></figure><p><strong>(2) 设置 <code>HF_HUB_ENABLE_HF_TRANSFER</code> 环境变量为 1。</strong><br><em>Linux</em></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HF_HUB_ENABLE_HF_TRANSFER=1</span><br></pre></td></tr></table></figure><p><em>Windows Powershell</em></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$env:HF_HUB_ENABLE_HF_TRANSFER</span> = <span class="number">1</span></span><br></pre></td></tr></table></figure><p>开启后使用方法同 <code>huggingface-cli</code> ：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">huggingface-cli download --resume-download bigscience/bloom-560m --local-dir bloom-560m</span><br></pre></td></tr></table></figure><p><em>注意：<strong>如果看到进度条，说明</strong></em> <em><strong><code>hf_transfer</code> </strong></em>*** 没开启成功！*** 例如以下情况：</p><p><code>--resume-download</code> 参数，指的是从上一次下载的地方继续，一般推荐总是加上该参数，断了方便继续。然而如果你一开始没有开启 <code>hf_transfer</code> ，下载中途停掉并设置环境变量开启，此时用 <code>--resume-download</code> 会由于不兼容导致 <code>hf_transfer</code> 开启失败！总之观察是否有进度条就可以知道有没有开启成功，没有进度条就说明开启成功！</p><div class="tags"><a href="/tags/Transformer/" rel="tag"><i class="ic i-tag"></i> Transformer</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2024-03-27 21:40:41" itemprop="dateModified" datetime="2024-03-27T21:40:41+08:00">2024-03-27</time></span></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>氨基酸小童鞋 <i class="ic i-at"><em>@</em></i>氨基酸小童鞋的博客</li><li class="link"><strong>本文链接：</strong> <a href="https://zhihao-a.github.io/2023/12/17/Transformer%E7%9B%B8%E5%85%B3%E6%96%87%E7%8C%AE%E6%80%BB%E7%BB%93/" title="Transformer相关文献总结">https://zhihao-a.github.io/2023/12/17/Transformer相关文献总结/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2023/12/17/Pandas&Numpy/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;s3.bmp.ovh&#x2F;imgs&#x2F;2023&#x2F;12&#x2F;17&#x2F;5e4a3be0bf1ee4cc.jpg" title="Pandas&amp;Numpy"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i></span><h3>Pandas&Numpy</h3></a></div><div class="item right"><a href="/2023/12/17/javaWeb%E5%85%A8%E6%A0%88/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;s3.bmp.ovh&#x2F;imgs&#x2F;2023&#x2F;12&#x2F;17&#x2F;8470e9e96dfe6744.jpg" title="javaWeb全栈"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i></span><h3>javaWeb全栈</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#huggingface-%E4%B8%8B%E8%BD%BD%E6%A8%A1%E5%9E%8B%E6%8C%87%E5%8D%97"><span class="toc-number">1.</span> <span class="toc-text">huggingFace 下载模型指南</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-huggingface-clihf_transfer"><span class="toc-number">1.1.</span> <span class="toc-text">1. huggingface-cli+hf_transfer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-huggingface-cli"><span class="toc-number">1.1.1.</span> <span class="toc-text">1.1 huggingface-cli</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-hf_transfe"><span class="toc-number">1.1.2.</span> <span class="toc-text">1.2 hf_transfe</span></a></li></ol></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="氨基酸小童鞋" data-src="/images/avatar.jpg"><p class="name" itemprop="name">氨基酸小童鞋</p><div class="description" itemprop="description">氨基酸小童鞋的博客</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">15</span> <span class="name">文章</span></a></div><div class="item tags"><a href="/tags/"><span class="count">10</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly96aGloYW8tYS5naXRodWIuY29tLw==" title="https:&#x2F;&#x2F;zhihao-a.github.com&#x2F;"><i class="ic i-github"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>文章</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>friends</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2023/12/17/Pandas&Numpy/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2023/12/17/javaWeb%E5%85%A8%E6%A0%88/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"></div><span><a href="/2024/12/09/MyBatis-Plus/" title="mybatis-plus">mybatis-plus</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2024/03/21/git%E9%85%8D%E7%BD%AE%E7%9B%B8%E5%85%B3/" title="git配置相关">git配置相关</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2024/08/28/docker/" title="docker">docker</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/12/17/Linux%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/" title="My First Post">My First Post</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/12/17/%E7%AE%97%E6%B3%95%E8%AE%AD%E7%BB%83%E5%8F%8A%E9%A2%98%E8%A7%A3%E6%B1%87%E6%80%BB/" title="算法训练及题解汇总">算法训练及题解汇总</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2024/03/02/Domain-adversarial-neural-networks-for-domain-generalizationwhen-it-works-and-how-to-improve/" title="Domain adversarial neural networks for domain generalizationwhen it works and how to improve">Domain adversarial neural networks for domain generalizationwhen it works and how to improve</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/12/17/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%A4%8D%E4%B9%A0/" title="数据结构复习">数据结构复习</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2024/03/02/Domain-Agnostic-Learning-with-Disentangled-Representations/" title="Domain Agnostic Learning with Disentangled Representations">Domain Agnostic Learning with Disentangled Representations</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/12/17/javaWeb%E5%85%A8%E6%A0%88/" title="javaWeb全栈">javaWeb全栈</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/12/17/%E7%AE%97%E6%B3%95%E5%8E%9F%E5%9E%8B/" title="算法原型">算法原型</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2023 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-garden hamster"></i> </span><span class="author" itemprop="copyrightHolder">氨基酸小童鞋 @ 氨基酸小童鞋</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">416k 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">6:18</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"2023/12/17/Transformer相关文献总结/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html>